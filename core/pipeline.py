import logging
import time
import uuid
from typing import Any, AsyncIterator, Dict

from database.session import session_mgr
from workflows.builder import create_workflow

from core.models import PipelineState, ProcessingMode

logger = logging.getLogger(__name__)


class AgentPipeline:
    def __init__(self):
        self.workflow = create_workflow()

    def run(
        self,
        query: str,
        session_id: str,
        language: str = "ä¸­æ–‡",
        enable_deep_thinking: bool = False,
        enable_web_search: bool = False,
    ) -> Dict[str, Any]:
        """åŒæ­¥è¿è¡Œï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        trace_id = str(uuid.uuid4())
        start_time = time.time()

        if enable_deep_thinking:
            mode = ProcessingMode.DEEP_THINKING
        elif enable_web_search:
            mode = ProcessingMode.WEB_SEARCH
        else:
            mode = ProcessingMode.BASIC

        logger.info(f"Pipeline started: trace_id={trace_id}, mode={mode}")

        session_mgr.add_message(session_id, "user", query)

        # è·å–ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆæœ€è¿‘ 5 è½®å¯¹è¯ï¼‰
        conversation_history = self._get_conversation_context(session_id, limit=10)

        initial_state: PipelineState = {
            "session_id": session_id,
            "domain": "general",
            "language": language,
            "query": query,
            "conversation_history": conversation_history,  # æ–°å¢ï¼šä¸Šä¸‹æ–‡è®°å¿†
            "processing_mode": mode,
            "understanding": None,
            "web_search_results": None,
            "initial_analysis": None,
            "reflection": None,
            "final_analysis": None,
            "artifacts": [],
            "final_answer": None,
            "error": None,
        }

        try:
            final_state = self.workflow.invoke(initial_state)

            for artifact in final_state.get("artifacts", []):
                session_mgr.save_artifact(session_id, artifact)

            answer = final_state.get("final_answer", "No response generated.")
            session_mgr.add_message(
                session_id,
                "assistant",
                answer,
                {"trace_id": trace_id, "mode": mode.value},
            )

            elapsed = time.time() - start_time
            logger.info(f"Pipeline completed: {elapsed:.2f}s")

            return {
                "trace_id": trace_id,
                "answer": answer,
                "understanding": final_state.get("understanding"),
                "web_search_results": final_state.get("web_search_results"),
                "reflection": final_state.get("reflection"),
                "final_analysis": final_state.get("final_analysis"),
                "artifacts": final_state.get("artifacts", []),
                "elapsed": elapsed,
                "processing_mode": mode.value,
            }

        except Exception as e:
            logger.error(f"Pipeline failed: {e}", exc_info=True)
            error_msg = f"Error: {str(e)}"
            session_mgr.add_message(session_id, "assistant", error_msg)
            return {"trace_id": trace_id, "answer": error_msg, "error": str(e)}

    async def run_streaming(
        self,
        query: str,
        session_id: str,
        language: str = "ä¸­æ–‡",
        enable_deep_thinking: bool = False,
        enable_web_search: bool = False,
    ) -> AsyncIterator[Dict[str, Any]]:
        """æµå¼è¿è¡Œï¼ˆå¼‚æ­¥ç”Ÿæˆå™¨ï¼‰"""
        trace_id = str(uuid.uuid4())
        start_time = time.time()

        if enable_deep_thinking:
            mode = ProcessingMode.DEEP_THINKING
        elif enable_web_search:
            mode = ProcessingMode.WEB_SEARCH
        else:
            mode = ProcessingMode.BASIC

        logger.info(f"Pipeline streaming started: trace_id={trace_id}, mode={mode}")

        session_mgr.add_message(session_id, "user", query)

        # è·å–ä¸Šä¸‹æ–‡è®°å¿†
        conversation_history = self._get_conversation_context(session_id, limit=10)

        # å‘é€åˆå§‹çŠ¶æ€
        yield {
            "type": "status",
            "content": "ğŸ¤” æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜...",
            "step": "understanding",
        }

        initial_state: PipelineState = {
            "session_id": session_id,
            "domain": "general",
            "language": language,
            "query": query,
            "conversation_history": conversation_history,
            "processing_mode": mode,
            "understanding": None,
            "web_search_results": None,
            "initial_analysis": None,
            "reflection": None,
            "final_analysis": None,
            "artifacts": [],
            "final_answer": None,
            "error": None,
        }

        try:
            # é€æ­¥æ‰§è¡Œ workflow å¹¶å‘é€è¿›åº¦
            current_state = initial_state

            # Understanding
            from agents.understanding import UnderstandingAgent

            understanding_agent = UnderstandingAgent()
            current_state = understanding_agent.understand(current_state)

            if current_state.get("error"):
                yield {"type": "error", "content": current_state["error"]}
                return

            yield {
                "type": "status",
                "content": f"âœ… å·²è¯†åˆ«ä¸º **{current_state['domain']}** é¢†åŸŸ",
                "step": "understanding_complete",
            }

            # Web Search (å¦‚æœéœ€è¦)
            understanding = current_state.get("understanding")
            if understanding and understanding.requires_web_search:
                yield {
                    "type": "status",
                    "content": "ğŸŒ æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯...",
                    "step": "searching",
                }

                from agents.search import WebSearchAgent

                search_agent = WebSearchAgent()
                current_state = search_agent.search(current_state)

                web_results = current_state.get("web_search_results")
                if web_results and web_results.results:
                    yield {
                        "type": "status",
                        "content": f"âœ… æ‰¾åˆ° {len(web_results.results)} æ¡ç›¸å…³ä¿¡æ¯",
                        "step": "search_complete",
                    }
            # ä½¿ç”¨æµå¼åˆ†æ
            yield {
                "type": "status",
                "content": "ğŸ“ æ­£åœ¨åˆ†æ...",
                "step": "analyzing",
            }
            from agents.analysis import InitialAnalysisAgent

            analysis_agent = InitialAnalysisAgent()

            # ä½¿ç”¨æµå¼åˆ†æ
            async for event in analysis_agent.analyze_streaming(current_state):
                event_type = event.get("type")

                if event_type == "content":
                    # ç›´æ¥ä¼ é€’å†…å®¹äº‹ä»¶
                    yield event
                elif event_type == "analysis_complete":
                    # æ›´æ–°çŠ¶æ€
                    current_state = event["state"]
                elif event_type == "error":
                    # ä¼ é€’é”™è¯¯
                    yield event
                    return

            # Deep Thinking (å¦‚æœå¯ç”¨)
            if mode == ProcessingMode.DEEP_THINKING:
                yield {
                    "type": "status",
                    "content": "ğŸ§  æ­£åœ¨æ·±åº¦åæ€...",
                    "step": "reflecting",
                }

                from agents.reflection import ReflectionAgent

                reflection_agent = ReflectionAgent()
                current_state = reflection_agent.reflect(current_state)

                if current_state.get("reflection"):
                    yield {
                        "type": "status",
                        "content": "âœ… åæ€å®Œæˆï¼Œæ­£åœ¨ä¼˜åŒ–ç­”æ¡ˆ...",
                        "step": "reflection_complete",
                    }

            # Code Generation (å¦‚æœéœ€è¦)
            if understanding and understanding.requires_code:
                yield {
                    "type": "status",
                    "content": "ğŸ’» æ­£åœ¨ç”Ÿæˆä»£ç ...",
                    "step": "coding",
                }

                from agents.analysis import DetailedAnalysisAgent

                detailed_agent = DetailedAnalysisAgent()
                current_state = detailed_agent.analyze(current_state)

                if (
                    current_state.get("final_analysis")
                    and current_state["final_analysis"].needs_code
                ):
                    from agents.code_generator import CodeGenerationAgent

                    code_agent = CodeGenerationAgent()
                    current_state = code_agent.generate(current_state)

                    if current_state.get("artifacts"):
                        yield {
                            "type": "status",
                            "content": f"âœ… å·²ç”Ÿæˆ {len(current_state['artifacts'])} ä¸ªä»£ç æ–‡ä»¶",
                            "step": "code_complete",
                        }

            # Synthesis
            yield {
                "type": "status",
                "content": "ğŸ“‹ æ­£åœ¨æ•´ç†æœ€ç»ˆç­”æ¡ˆ...",
                "step": "synthesizing",
            }

            from agents.synthesis import SynthesisAgent

            synthesis_agent = SynthesisAgent()
            current_state = synthesis_agent.synthesize(current_state)

            # ä¿å­˜ artifacts
            for artifact in current_state.get("artifacts", []):
                session_mgr.save_artifact(session_id, artifact)

            # å‘é€æœ€ç»ˆç­”æ¡ˆ
            answer = current_state.get("final_answer", "No response generated.")
            session_mgr.add_message(
                session_id,
                "assistant",
                answer,
                {"trace_id": trace_id, "mode": mode.value},
            )

            elapsed = time.time() - start_time

            yield {
                "type": "final",
                "content": answer,
                "metadata": {
                    "trace_id": trace_id,
                    "elapsed": elapsed,
                    "understanding": current_state.get("understanding"),
                    "artifacts": current_state.get("artifacts", []),
                },
            }

        except Exception as e:
            logger.error(f"Pipeline streaming failed: {e}", exc_info=True)
            yield {"type": "error", "content": f"å¤„ç†å‡ºé”™: {str(e)}"}

    def _get_conversation_context(self, session_id: str, limit: int = 10) -> str:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘ N æ¡æ¶ˆæ¯ï¼‰"""
        messages = session_mgr.get_messages(session_id, limit=limit)

        if not messages:
            return ""

        # æ ¼å¼åŒ–ä¸ºå¯¹è¯å†å²
        context_parts = []
        for msg in messages[-limit:]:  # åªå–æœ€å limit æ¡
            role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
            content = msg["content"][:200]  # æ¯æ¡é™åˆ¶ 200 å­—ç¬¦
            context_parts.append(f"{role}: {content}")

        return "\n".join(context_parts)


pipeline = AgentPipeline()
